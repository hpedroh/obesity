{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07df6131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 1. IMPORTAÇÕES E CONFIGURAÇÕES GERAIS\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import shap\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Configuração de Estilo Global\n",
    "sns.set_context(\"notebook\", font_scale=1.1)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3949d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 2. CONFIGURAÇÃO DO PROJETO (CONSTANTES)\n",
    "# ==============================================================================\n",
    "class Config:\n",
    "    \"\"\"Centraliza constantes, caminhos e configurações do projeto.\"\"\"\n",
    "    \n",
    "    # Caminhos\n",
    "    BASE_DIR = Path.cwd()\n",
    "    DATA_PATH = BASE_DIR.parent / 'data' / 'obesity.csv'\n",
    "    OUTPUT_MODEL_DIR = BASE_DIR.parent / 'saved_model'\n",
    "    OUTPUT_DOCS_DIR = BASE_DIR.parent / 'docs' / 'assets'\n",
    "    \n",
    "    # Colunas\n",
    "    TARGET_COL = 'Obesity'\n",
    "    COLS_TO_ROUND = ['FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']\n",
    "    \n",
    "    # Definição de Features\n",
    "    NUMERIC_FEATURES = ['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE']\n",
    "    ONE_HOT_FEATURES = ['Gender', 'family_history', 'FAVC', 'SMOKE', 'SCC', 'MTRANS']\n",
    "    ORDINAL_FEATURES = ['CAEC', 'CALC']\n",
    "    \n",
    "    # Ordem das Categorias Ordinais\n",
    "    ORDER_CAEC = ['no', 'Sometimes', 'Frequently', 'Always']\n",
    "    ORDER_CALC = ['no', 'Sometimes', 'Frequently', 'Always']\n",
    "    \n",
    "    # Dicionários de Tradução (PT-BR)\n",
    "    TRANSLATE_CLASSES = {\n",
    "        'Insufficient_Weight': 'Abaixo do Peso',\n",
    "        'Normal_Weight': 'Peso Normal',\n",
    "        'Overweight_Level_I': 'Sobrepeso I',\n",
    "        'Overweight_Level_II': 'Sobrepeso II',\n",
    "        'Obesity_Type_I': 'Obesidade I',\n",
    "        'Obesity_Type_II': 'Obesidade II',\n",
    "        'Obesity_Type_III': 'Obesidade III'\n",
    "    }\n",
    "    \n",
    "    TRANSLATE_FEATURES = {\n",
    "        'Age': 'Idade', 'Height': 'Altura', 'Weight': 'Peso',\n",
    "        'family_history': 'Histórico Familiar', 'FAVC': 'Consumo Calórico',\n",
    "        'FCVC': 'Consumo de Vegetais', 'NCP': 'Refeições/Dia',\n",
    "        'CAEC': 'Comer entre Refeições', 'SMOKE': 'Fumante',\n",
    "        'CH2O': 'Consumo de Água', 'SCC': 'Monitora Calorias',\n",
    "        'FAF': 'Atividade Física', 'TUE': 'Tempo de Tela',\n",
    "        'CALC': 'Consumo de Álcool', 'MTRANS': 'Transporte',\n",
    "        'Gender': 'Gênero'\n",
    "    }\n",
    "    \n",
    "    TRANSLATE_VALUES = {\n",
    "        'yes': 'Sim', 'no': 'Não',\n",
    "        'Male': 'Masc.', 'Female': 'Fem.',\n",
    "        'Automobile': 'Carro', 'Public_Transportation': 'Transp. Público',\n",
    "        'Walking': 'Caminhada', 'Motorbike': 'Moto', 'Bike': 'Bicicleta',\n",
    "        'Sometimes': 'Às vezes', 'Frequently': 'Freq.', 'Always': 'Sempre'\n",
    "    }\n",
    "\n",
    "# Garante que diretórios de saída existem\n",
    "Config.OUTPUT_MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "Config.OUTPUT_DOCS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2001c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 3. FUNÇÕES AUXILIARES (CORE)\n",
    "# ==============================================================================\n",
    "\n",
    "def carregar_e_limpar_dados(caminho_arquivo: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Carrega o dataset e aplica limpezas iniciais (arredondamento).\n",
    "    \n",
    "    Args:\n",
    "        caminho_arquivo (Path): Caminho para o CSV.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame limpo.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(caminho_arquivo)\n",
    "    except FileNotFoundError:\n",
    "        # Tenta carregar do diretório atual como fallback\n",
    "        print(f\"Arquivo não encontrado em {caminho_arquivo}. Tentando local...\")\n",
    "        df = pd.read_csv('obesity.csv')\n",
    "        \n",
    "    # Arredonda colunas numéricas que possuem ruído decimal\n",
    "    for col in Config.COLS_TO_ROUND:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].round().astype(int)\n",
    "            \n",
    "    print(f\"Dados carregados. Shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "def construir_pipeline() -> Pipeline:\n",
    "    \"\"\"\n",
    "    Constrói o pipeline de pré-processamento e modelagem.\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "        Pipeline: Objeto Scikit-Learn pronto para treino.\n",
    "    \"\"\"\n",
    "    # 1. Transformadores Específicos\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    ordinal_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('ordinal_encoder', OrdinalEncoder(\n",
    "            categories=[Config.ORDER_CAEC, Config.ORDER_CALC],\n",
    "            handle_unknown='use_encoded_value',\n",
    "            unknown_value=-1\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    one_hot_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    # 2. Pré-processador Geral (ColumnTransformer)\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, Config.NUMERIC_FEATURES),\n",
    "            ('cat_onehot', one_hot_transformer, Config.ONE_HOT_FEATURES),\n",
    "            ('cat_ordinal', ordinal_transformer, Config.ORDINAL_FEATURES)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # 3. Pipeline Final com Random Forest\n",
    "    return Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "\n",
    "def limpar_nome_feature(nome_sujo: str) -> str:\n",
    "    \"\"\"\n",
    "    Traduz e limpa nomes técnicos de features gerados pelo Pipeline.\n",
    "    Ex: 'cat_onehot__Gender_Male' -> 'Gênero: Masc.'\n",
    "    \"\"\"\n",
    "    # Remove prefixos técnicos (ex: cat_onehot__)\n",
    "    nome_limpo = nome_sujo.split('__')[-1]\n",
    "    \n",
    "    # Tradução direta\n",
    "    if nome_limpo in Config.TRANSLATE_FEATURES:\n",
    "        return Config.TRANSLATE_FEATURES[nome_limpo]\n",
    "    \n",
    "    # Tradução composta (Feature + Valor OneHot)\n",
    "    for feature_eng, feature_pt in Config.TRANSLATE_FEATURES.items():\n",
    "        if feature_eng in nome_limpo:\n",
    "            valor_eng = nome_limpo.replace(f\"{feature_eng}_\", \"\")\n",
    "            valor_pt = Config.TRANSLATE_VALUES.get(valor_eng, valor_eng)\n",
    "            return f\"{feature_pt}: {valor_pt}\"\n",
    "            \n",
    "    return nome_limpo\n",
    "\n",
    "def salvar_modelo(pipeline, X_train):\n",
    "    \"\"\"Salva o modelo treinado e seus metadados essenciais.\"\"\"\n",
    "    \n",
    "    # Salva Pipeline\n",
    "    path_model = Config.OUTPUT_MODEL_DIR / 'modelo_obesidade.joblib'\n",
    "    joblib.dump(pipeline, path_model)\n",
    "    \n",
    "    # Salva Metadados\n",
    "    model_metadata = {\n",
    "        'features_expected': X_train.columns.tolist(),\n",
    "        'numeric_features': Config.NUMERIC_FEATURES,\n",
    "        'one_hot_features': Config.ONE_HOT_FEATURES,\n",
    "        'ordinal_features': Config.ORDINAL_FEATURES,\n",
    "        'classes': pipeline.classes_.tolist()\n",
    "    }\n",
    "    path_meta = Config.OUTPUT_MODEL_DIR / 'model_metadata.joblib'\n",
    "    joblib.dump(model_metadata, path_meta)\n",
    "    \n",
    "    print(f\"\\nModelo salvo em: {path_model}\")\n",
    "    print(f\"Metadados salvos em: {path_meta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f46d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 4. FUNÇÕES DE VISUALIZAÇÃO (DOCUMENTAÇÃO)\n",
    "# ==============================================================================\n",
    "\n",
    "def plotar_matriz_confusao(y_test, y_pred, classes, output_dir):\n",
    "    \"\"\"Gera e salva a Matriz de Confusão traduzida.\"\"\"\n",
    "    labels_traduzidos = [Config.TRANSLATE_CLASSES.get(l, l) for l in classes]\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=classes)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(\n",
    "        cm, annot=True, fmt='d', cmap='Blues',\n",
    "        xticklabels=labels_traduzidos, yticklabels=labels_traduzidos, cbar=False\n",
    "    )\n",
    "    plt.title('Matriz de Confusão (Dados de Teste)', fontsize=16, pad=20)\n",
    "    plt.xlabel('Predição do Modelo', fontsize=12)\n",
    "    plt.ylabel('Classificação Real', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'matriz_confusao.png', dpi=300)\n",
    "    plt.close()\n",
    "    print(\"Imagem salva: matriz_confusao.png\")\n",
    "\n",
    "def plotar_feature_importance(pipeline, output_dir):\n",
    "    \"\"\"Extrai, limpa e plota a importância das features.\"\"\"\n",
    "    # Recupera nomes das features transformadas\n",
    "    preprocessor = pipeline.named_steps['preprocessor']\n",
    "    raw_names = []\n",
    "    \n",
    "    # Numéricas\n",
    "    raw_names.extend(Config.NUMERIC_FEATURES)\n",
    "    # OneHot\n",
    "    ohe = preprocessor.named_transformers_['cat_onehot']['onehot']\n",
    "    raw_names.extend(ohe.get_feature_names_out(Config.ONE_HOT_FEATURES))\n",
    "    # Ordinais\n",
    "    raw_names.extend(Config.ORDINAL_FEATURES)\n",
    "    \n",
    "    # Limpa nomes e pega importâncias\n",
    "    clean_names = [limpar_nome_feature(f) for f in raw_names]\n",
    "    importances = pipeline.named_steps['classifier'].feature_importances_\n",
    "    \n",
    "    # DataFrame para plotagem\n",
    "    df_imp = pd.DataFrame({'Feature': clean_names, 'Importance': importances})\n",
    "    df_imp = df_imp.groupby('Feature').sum().reset_index() # Agrupa duplicatas se houver\n",
    "    df_imp = df_imp.sort_values('Importance', ascending=False).head(15)\n",
    "\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    ax = sns.barplot(x='Importance', y='Feature', data=df_imp, palette='viridis', hue='Feature', legend=False)\n",
    "    plt.title('Fatores de Maior Impacto na Predição', fontsize=16)\n",
    "    \n",
    "    for i in ax.containers:\n",
    "        ax.bar_label(i, fmt='%.3f', padding=5)\n",
    "        \n",
    "    sns.despine(left=True, bottom=False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'feature_importance.png', dpi=300)\n",
    "    plt.close()\n",
    "    print(\"Imagem salva: feature_importance.png\")\n",
    "\n",
    "def plotar_shap_waterfall(pipeline, X_test, output_dir):\n",
    "    \"\"\"Gera um gráfico Waterfall do SHAP para um caso específico (Obesidade III).\"\"\"\n",
    "    # Configura estilo específico para SHAP\n",
    "    plt.style.use('default') \n",
    "    \n",
    "    class_interest = 'Obesity_Type_III'\n",
    "    if class_interest not in pipeline.classes_:\n",
    "        return\n",
    "\n",
    "    class_idx = list(pipeline.classes_).index(class_interest)\n",
    "    preds = pipeline.predict(X_test)\n",
    "    indices = np.where(preds == class_interest)[0]\n",
    "\n",
    "    if len(indices) == 0:\n",
    "        print(\"Nenhum caso de Obesidade III encontrado para gerar SHAP.\")\n",
    "        return\n",
    "\n",
    "    # Prepara dados\n",
    "    sample_idx = indices[0]\n",
    "    X_sample = X_test.iloc[[sample_idx]]\n",
    "    X_trans = pipeline.named_steps['preprocessor'].transform(X_sample)\n",
    "\n",
    "    # Calcula SHAP\n",
    "    model = pipeline.named_steps['classifier']\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer(X_trans)\n",
    "    explanation = shap_values[0, :, class_idx]\n",
    "\n",
    "    # Traduz nomes\n",
    "    preprocessor = pipeline.named_steps['preprocessor']\n",
    "    raw_names = (Config.NUMERIC_FEATURES + \n",
    "                 list(preprocessor.named_transformers_['cat_onehot']['onehot'].get_feature_names_out(Config.ONE_HOT_FEATURES)) + \n",
    "                 Config.ORDINAL_FEATURES)\n",
    "    explanation.feature_names = [limpar_nome_feature(f) for f in raw_names]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    shap.plots.waterfall(explanation, max_display=12, show=False)\n",
    "    plt.title(f\"Explicação: {Config.TRANSLATE_CLASSES.get(class_interest, class_interest)}\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'shap_waterfall.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Restaura estilo\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    print(\"Imagem salva: shap_waterfall.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46d13e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados carregados. Shape: (2111, 17)\n",
      "\n",
      "Iniciando treinamento do Pipeline...\n",
      "Modelo treinado com sucesso.\n",
      "\n",
      "Acurácia no Teste: 94.09%\n",
      "Cross-Validation (Média): 92.24% (+/- 10.44%)\n",
      "\n",
      "Modelo salvo em: c:\\Users\\Pedro\\Desktop\\Git\\obesity\\saved_model\\modelo_obesidade.joblib\n",
      "Metadados salvos em: c:\\Users\\Pedro\\Desktop\\Git\\obesity\\saved_model\\model_metadata.joblib\n",
      "\n",
      "Gerando assets para documentação...\n",
      "Imagem salva: matriz_confusao.png\n",
      "Imagem salva: feature_importance.png\n",
      "Imagem salva: shap_waterfall.png\n",
      "\n",
      "Processo finalizado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 5. EXECUÇÃO PRINCIPAL\n",
    "# ==============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # 1. Carregamento\n",
    "    df = carregar_e_limpar_dados(Config.DATA_PATH)\n",
    "    \n",
    "    # 2. Split\n",
    "    X = df.drop(Config.TARGET_COL, axis=1)\n",
    "    y = df[Config.TARGET_COL]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    # 3. Treinamento\n",
    "    print(\"\\nIniciando treinamento do Pipeline...\")\n",
    "    model_pipeline = construir_pipeline()\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "    print(\"Modelo treinado com sucesso.\")\n",
    "    \n",
    "    # 4. Avaliação\n",
    "    acc = model_pipeline.score(X_test, y_test)\n",
    "    print(f\"\\nAcurácia no Teste: {acc:.2%}\")\n",
    "    \n",
    "    # Cross Validation (rápido check)\n",
    "    cv_scores = cross_val_score(model_pipeline, X, y, cv=5, scoring='accuracy')\n",
    "    print(f\"Cross-Validation (Média): {cv_scores.mean():.2%} (+/- {cv_scores.std():.2%})\")\n",
    "    \n",
    "    # 5. Persistência\n",
    "    salvar_modelo(model_pipeline, X_train)\n",
    "    \n",
    "    # 6. Geração de Documentação Visual\n",
    "    print(\"\\nGerando assets para documentação...\")\n",
    "    y_pred = model_pipeline.predict(X_test)\n",
    "    \n",
    "    plotar_matriz_confusao(y_test, y_pred, model_pipeline.classes_, Config.OUTPUT_DOCS_DIR)\n",
    "    plotar_feature_importance(model_pipeline, Config.OUTPUT_DOCS_DIR)\n",
    "    plotar_shap_waterfall(model_pipeline, X_test, Config.OUTPUT_DOCS_DIR)\n",
    "    \n",
    "    print(\"\\nProcesso finalizado com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
